---
title: "MixDiff: a framework to reconstruct dataset with missing or erroneous data for outbreaks intervention"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Method

##Pathways

There exist four different pathays depending if the case has been hospitalised and/or survived. The date associated with the four health seeking pathways are given in the following table: 

|                  | Onset | Hospitalisation | Death | Discharge | Report |
|------------------|-------|-----------------|-------|-----------|--------|
| $HD$             |   X   |        X        |   X   |           |    X   |
| $H\bar{D}$       |   X   |        X        |       |     X     |    X   |
| $\bar{HD}$       |   X   |                 |   X   |           |    X   |
| $\bar{H}\bar{D}$ |   X   |                 |       |           |    X   |

## Notations

For each individual $i$, we denote $y_i^k$ $(k=1, \ldots, n_{g_i})$ the observed data for that individual. 
The number of observed data $n_{g_i}$ can depend on characteristics of the individual, defined by a grouping so that individual $i$ is in group $g_i$. 

Here, we consider observed data as being epidemiologically relevant dates, which depend on the path of the individual (see table above): if the individual was hospitalised and died ($g_i=HD$) or was hospitalised and did not die ($g_i=H\bar{D}$), $n_{g_i}=4$; if the individual was not hospitalised and died ($g_i=\bar{H}D$), $n_{g_i}=3$; if the individual was not hospitalised and died ($g_i=\bar{H}\bar{D}$), $n_{g_i}=2$.

We are interested in inferring the timing of the different steps of the healthcare pathways depending on the group $g_{i}$. To fully describe the healthcare pathway, we need to define the onset of the disease (no other date should be anterior) and then $n_{g_i}-1$ delays to reach the $n_{g_i}-1$ remaining enpoints. Any pairs of points can be chosen, providing that there exists a path from the origin to the endpoints. For example, in the case of the group $HD$, (onset -> hospitalisation, hospitalisation -> death, onset -> report) is a valid representation, while (onset -> hospitalisation, hospitalisation -> Death, onset -> report)
$\Delta_i^k$ the delay taken by individual $i$ for the $k$th delay distribution 

We assume that each data (here date) can have been recorded with error, or can be missing in the observations. Hence we introduce augmented data $D_i^k$ $(k=1, \ldots, n_{g_i})$, where $D_i^k$ is the true data corresponding to the observed data $y_i^k$. 

## Likelihood

### Observation level

The data from the healthcare pathways can be missing or recorded, and, if recorded, can be correct or erroneous. To each observed data entry $y_i^k$ is thus associated an indicator function $E_i^k \in \{-1,0,1 \}$ (missing, recorded and no error, recorded and erroneous). We have
$$P(E_i^k=1|E_i^k \neq -1)= Bernoulli(\zeta)$$
with $\zeta$ the error probability. The likelihood associated with the observed data $y_i^k$ conditional on the true data $D_i^k$ is thus:
$$P(y_i^k|D_i^k,E_i^k=0)=\delta_{y_i^k,D_i^k}$$
$$P(y_i^k|D_i^k,E_i^k=1)=h_{\theta_h}\left(D_i^k\right)$$
$$P(y_i^k|D_i^k,E_i^k=-1)=1$$

Here we assume that any date between $T$ and $T_{0}$ are equally likely to be recorded and thus $h_{\theta_h}\left(D_i^k\right)=\frac{1}{T-T_{0}}$.

NOTE: discuss what $h_{\theta_h}$ should be; could include conditions such as error on onset date > error on death date. Also think about the space of possible errors - if wider than h is smaller and moves towards E=1 might be difficult to achieve. What happens if T_0 is ridiculously early or T ridiculously late in the dataset - this will affect the likelihood. 

### Difference level

This level describes the difference between two observations: 
for $k\geq 2$, $P\left(D_i^k|D_i^{k-1}, g_i\right) = f_{k-1, k}^{g_i}\left(D_i^{k}-D_i^{k-1}\right)$. 

We use discretised gamma distributions for $f_{k-1, k}^{g_i}$ with shape and scale being noted respectively $\alpha_{k-1, k}^{g_i}$ and $\beta_{k-1, k}^{g_i}$. 

<!--In our example, we assume that the distribution of the delay between exposure and onset $f_{E, O}^{g_i}=f_{E, O}$ does not depend on the group - NOT RELEVANT FOR NOW AS NOT CONSIDERING EXPOSURE DATE -->

### Full posterior distribution

The joint posteior distribution of parameters and augmented data given observed data is:

$\begin{aligned}
P\left(\zeta, \alpha, \beta, D, E | g, y\right) \propto& P\left(\zeta, \alpha, \beta, D, E, g, y\right) \\
  \propto& P\left(y | D, E, \zeta, \alpha, \beta, g\right) P\left(E | \zeta, D, \alpha, \beta, g\right) P\left(D | \zeta, \alpha, \beta, g\right) P\left(\zeta\right) P\left(\alpha\right) P\left(\beta\right)\\
    \propto& P\left(y | D, E\right) P\left(E | \zeta\right) P\left(D | \zeta, \alpha, \beta, g\right)P\left(\zeta\right) P\left(\alpha\right) P\left(\beta\right)
\end{aligned}$

where $P\left(D | \zeta, \alpha, \beta, g\right) \propto \prod_i \prod_{k=2}^{n_{g_i}} P\left( D_i^k | D_i^{k-1}, \alpha, \beta, g \right)$ (assuming a uniform prior for $D_i^1$). 

## Priors

We use an informative beta prior for $\zeta$, and uninformative flat exponential priors for $\mu$ and $\sigma$, the mean and standard deviations of all delays. 

## Moves

TO WRITE BETTER
Metropolis algorithm with Lognormal proposal for $\mu$, $\sigma$
Beta Gibbs sampler for $\zeta$
Metropolis random walk +/-1 for dates $D$, with $E$ being automatically updated accordingly. Only a fraction of dates updates at each iteration. 



